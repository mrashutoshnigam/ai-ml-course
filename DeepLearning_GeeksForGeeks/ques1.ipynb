{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11d7cd21",
   "metadata": {},
   "source": [
    "Implement the Sparse auto-encoder and the Contractive Auto-encoder. Use the MNIST digit dataset for\n",
    "training your network. Use the U-Net auto-encoder architecture for encoder and decoder without skip\n",
    "connections. Let E be the trained encoder and D be the trained decoder, h = E(I) be the embedding of\n",
    "an image I and let ˆI = D(h) be the output of the decoder.\n",
    "(a) (20 points) Plot the t-sne (use inbuilt function) on the embeddings obtained using the respective\n",
    "auto-encoders. Color the clusters using the respective ground-truth class labels.\n",
    "(b) (20 points) Randomly take two images I1 and I2 from two different digit classes. Let h1 = E(I1)\n",
    "and h2 = E(I2) be the embeddings for these images, respectively. Construct another image Iα =\n",
    "αI1+(1−α)I2 for α = 0, 0.2, 0.4, 0.6, 0.8, 1. Find the embedding hα of this image Iα for all values of α\n",
    "by passing it through the encoder. Also, consider the approximate embedding h\n",
    "′\n",
    "α = αh1 + (1−α)h2\n",
    "by using directly the embeddings of the images I1 and I2. Also, find ˆIα = D(hα) and ˆI\n",
    "′\n",
    "α = D(h\n",
    "′\n",
    "α).\n",
    "Plot the images ˆIα and ˆI\n",
    "′\n",
    "α side by side for different values of α. Do this for 20 pairs (I1, I2). Report\n",
    "PSNR between ˆIα and ˆI\n",
    "′\n",
    "α and find ∥hˆ\n",
    "α − hˆ′\n",
    "α∥2 for all values of alpha.\n",
    "(c) (20 points) After training the autoencoders, you want to check if the embeddings of different digits\n",
    "are different and embeddings within a class are similar. For this purpose, you propose to perform\n",
    "the classification of the digits based on the embeddings obtained by the encoders and check the\n",
    "accuracy of classifications for each of the Auto-encoder. Report the classification accuracy for each\n",
    "of the AE and report which one is better. Use any inbuilt classifier to solve the classification\n",
    "problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "418cfc89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in e:\\ai\\ai-ml-course\\venv\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: numpy in e:\\ai\\ai-ml-course\\venv\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: pandas in e:\\ai\\ai-ml-course\\venv\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: matplotlib in e:\\ai\\ai-ml-course\\venv\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: scikit-learn in e:\\ai\\ai-ml-course\\venv\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: seaborn in e:\\ai\\ai-ml-course\\venv\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in e:\\ai\\ai-ml-course\\venv\\lib\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in e:\\ai\\ai-ml-course\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in e:\\ai\\ai-ml-course\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in e:\\ai\\ai-ml-course\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in e:\\ai\\ai-ml-course\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in e:\\ai\\ai-ml-course\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in e:\\ai\\ai-ml-course\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in e:\\ai\\ai-ml-course\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in e:\\ai\\ai-ml-course\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in e:\\ai\\ai-ml-course\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (5.29.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in e:\\ai\\ai-ml-course\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in e:\\ai\\ai-ml-course\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in e:\\ai\\ai-ml-course\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in e:\\ai\\ai-ml-course\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in e:\\ai\\ai-ml-course\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in e:\\ai\\ai-ml-course\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in e:\\ai\\ai-ml-course\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.70.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in e:\\ai\\ai-ml-course\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in e:\\ai\\ai-ml-course\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in e:\\ai\\ai-ml-course\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in e:\\ai\\ai-ml-course\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in e:\\ai\\ai-ml-course\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in e:\\ai\\ai-ml-course\\venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\ai\\ai-ml-course\\venv\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in e:\\ai\\ai-ml-course\\venv\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in e:\\ai\\ai-ml-course\\venv\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in e:\\ai\\ai-ml-course\\venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in e:\\ai\\ai-ml-course\\venv\\lib\\site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in e:\\ai\\ai-ml-course\\venv\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in e:\\ai\\ai-ml-course\\venv\\lib\\site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in e:\\ai\\ai-ml-course\\venv\\lib\\site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in e:\\ai\\ai-ml-course\\venv\\lib\\site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in e:\\ai\\ai-ml-course\\venv\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in e:\\ai\\ai-ml-course\\venv\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in e:\\ai\\ai-ml-course\\venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in e:\\ai\\ai-ml-course\\venv\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in e:\\ai\\ai-ml-course\\venv\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in e:\\ai\\ai-ml-course\\venv\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\ai\\ai-ml-course\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\ai\\ai-ml-course\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\ai\\ai-ml-course\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\ai\\ai-ml-course\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in e:\\ai\\ai-ml-course\\venv\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in e:\\ai\\ai-ml-course\\venv\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in e:\\ai\\ai-ml-course\\venv\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in e:\\ai\\ai-ml-course\\venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in e:\\ai\\ai-ml-course\\venv\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in e:\\ai\\ai-ml-course\\venv\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in e:\\ai\\ai-ml-course\\venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow numpy pandas matplotlib scikit-learn seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd618d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "db679a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 128\n",
    "epochs = 20\n",
    "learning_rate = 0.001\n",
    "sparse_lambda = 1e-3  # Sparsity penalty\n",
    "contractive_lambda = 1e-4  # Contractive penalty\n",
    "rho = 0.05  # Target sparsity\n",
    "\n",
    "# Load and preprocess MNIST dataset\n",
    "(x_train, _), (_, _) = mnist.load_data()\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_train = np.expand_dims(x_train, axis=-1)  # Shape: (60000, 28, 28, 1)\n",
    "x_train = (x_train - 0.1307) / 0.3081  # Normalize as per PyTorch example\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(x_train).shuffle(60000).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c9dfbb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def encoder_block(inputs, num_filters):\n",
    "    x = layers.Conv2D(num_filters, 3, padding='same')(inputs)\n",
    "    x = layers.Activation('relu')(x)    \n",
    "    x = layers.Conv2D(num_filters, 3, padding='same')(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.MaxPool2D(pool_size=(2, 2), strides=2)(x)\n",
    "    return x\n",
    "    \n",
    "def decoder_block(inputs, num_filters):\n",
    "    x = layers.Conv2DTranspose(num_filters, (2, 2), strides=2, padding='same')(inputs)\n",
    "    x = layers.Conv2D(num_filters, 3, padding='same')(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(num_filters, 3, padding='same')(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "class UNetAutoEncoderArchitecture():\n",
    "    def build_encoder(self, input_shape=(28, 28, 1)):\n",
    "        inputs = layers.Input(shape=input_shape)\n",
    "        x = encoder_block(inputs, 64)\n",
    "        x = encoder_block(x, 128)\n",
    "        x = encoder_block(x, 256)        \n",
    "        return models.Model(inputs=inputs, outputs=x, name='encoder')\n",
    "    \n",
    "    def build_decoder(self, input_shape=(128,)):\n",
    "        inputs = layers.Input(shape=input_shape)\n",
    "        x = layers.Dense(4*4*256, activation='relu')(inputs)\n",
    "        x = layers.Reshape((4, 4, 256))(x)\n",
    "        x = decoder_block(x, 256)\n",
    "        x = decoder_block(x, 128)\n",
    "        x = decoder_block(x, 64)\n",
    "        outputs = layers.Conv2D(1, 1, padding='same', activation='sigmoid')(x)        \n",
    "        return models.Model(inputs=inputs, outputs=outputs, name='decoder')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c5b2d526",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseAutoencoder(models.Model):\n",
    "    def __init__(self, input_shape):\n",
    "        super(SparseAutoencoder, self).__init__()       \n",
    "        self.encoder = UNetAutoEncoderArchitecture().build_encoder(input_shape)\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.latent_dense = layers.Dense(128, activation='relu', name='latent_space')\n",
    "        self.decoder = UNetAutoEncoderArchitecture().build_decoder(input_shape=(128,))\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        encoded = self.encoder(inputs)\n",
    "        flattened = self.flatten(encoded)\n",
    "        latent = self.latent_dense(flattened)\n",
    "        decoded = self.decoder(latent)\n",
    "        return decoded\n",
    "        \n",
    "    def encode(self, inputs):\n",
    "        encoded = self.encoder(inputs)\n",
    "        flattened = self.flatten(encoded)\n",
    "        return self.latent_dense(flattened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0e10c422",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContractiveAutoencoder(models.Model):\n",
    "    def __init__(self, input_shape):\n",
    "        super(ContractiveAutoencoder, self).__init__()\n",
    "        self.encoder = UNetAutoEncoderArchitecture().build_encoder()\n",
    "        self.decoder = UNetAutoEncoderArchitecture().build_decoder()\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.dense = layers.Dense(128, activation='relu')\n",
    "        self.output_layer = layers.Dense(np.prod(input_shape), activation='sigmoid')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.encoder(inputs)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b83fd024",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_loss(y_true, y_pred):\n",
    "    mse_loss = tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "    model = tf.keras.backend.get_value(sparse_ae.latent_dense)\n",
    "    rho_hat = tf.reduce_mean(model, axis=0)\n",
    "    kl_div = rho * tf.math.log(rho / rho_hat) + (1 - rho) * tf.math.log((1 - rho) / (1 - rho_hat))\n",
    "    kl_div = tf.reduce_sum(kl_div)    \n",
    "    return mse_loss + sparse_lambda * kl_div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2d893f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "None values not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# For testing purposes, use MSE loss first\u001b[39;00m\n\u001b[0;32m      3\u001b[0m sparse_ae\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate), loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[43msparse_ae\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\AI\\ai-ml-course\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32me:\\AI\\ai-ml-course\\venv\\Lib\\site-packages\\optree\\ops.py:766\u001b[0m, in \u001b[0;36mtree_map\u001b[1;34m(func, tree, is_leaf, none_is_leaf, namespace, *rests)\u001b[0m\n\u001b[0;32m    764\u001b[0m leaves, treespec \u001b[38;5;241m=\u001b[39m _C\u001b[38;5;241m.\u001b[39mflatten(tree, is_leaf, none_is_leaf, namespace)\n\u001b[0;32m    765\u001b[0m flat_args \u001b[38;5;241m=\u001b[39m [leaves] \u001b[38;5;241m+\u001b[39m [treespec\u001b[38;5;241m.\u001b[39mflatten_up_to(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rests]\n\u001b[1;32m--> 766\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtreespec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflat_args\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: None values not supported."
     ]
    }
   ],
   "source": [
    "sparse_ae = SparseAutoencoder(input_shape=(28, 28, 1))\n",
    "# For testing purposes, use MSE loss first\n",
    "sparse_ae.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss='mse')\n",
    "sparse_ae.fit(train_dataset, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995e0c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed = autoencoder.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26466c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # Original images\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28), cmap='gray')\n",
    "    plt.title(\"Original\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Reconstructed images\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(reconstructed[i].reshape(28, 28), cmap='gray')\n",
    "    plt.title(\"Reconstructed\")\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2e835d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "None values not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 44\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Compile and train\u001b[39;00m\n\u001b[0;32m     43\u001b[0m sparse_ae\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate), loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 44\u001b[0m \u001b[43msparse_ae\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# For visualization and later use\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Remember to modify the sparse_loss function if you want to implement it later\u001b[39;00m\n",
      "File \u001b[1;32me:\\AI\\ai-ml-course\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32me:\\AI\\ai-ml-course\\venv\\Lib\\site-packages\\optree\\ops.py:766\u001b[0m, in \u001b[0;36mtree_map\u001b[1;34m(func, tree, is_leaf, none_is_leaf, namespace, *rests)\u001b[0m\n\u001b[0;32m    764\u001b[0m leaves, treespec \u001b[38;5;241m=\u001b[39m _C\u001b[38;5;241m.\u001b[39mflatten(tree, is_leaf, none_is_leaf, namespace)\n\u001b[0;32m    765\u001b[0m flat_args \u001b[38;5;241m=\u001b[39m [leaves] \u001b[38;5;241m+\u001b[39m [treespec\u001b[38;5;241m.\u001b[39mflatten_up_to(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rests]\n\u001b[1;32m--> 766\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtreespec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflat_args\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: None values not supported."
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
