{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740b891b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow numpy matplotlib scikit-learn seaborn tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65789ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns \n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ec01d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 128\n",
    "epochs = 20\n",
    "learning_rate = 0.001\n",
    "sparse_lambda = 1e-3  # Sparsity penalty\n",
    "contractive_lambda = 1e-4  # Contractive penalty\n",
    "rho = 0.05  # Target sparsity\n",
    "epsilon = 1e-6\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "x_train = np.expand_dims(x_train, axis=-1)  # Shape: (60000, 28, 28, 1)\n",
    "x_test = np.expand_dims(x_test, axis=-1)  # Shape: (10000, 28, 28, 1)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(x_train).cache().shuffle(60000).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f7e705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-Net-like Encoder\n",
    "def build_encoder():\n",
    "    inputs = layers.Input(shape=(28, 28, 1))\n",
    "    x = layers.Conv2D(64, 3, padding='same', activation='relu')(inputs)  # 28x28x64\n",
    "    x = layers.MaxPooling2D(2)(x)  # 14x14x64\n",
    "    x = layers.Conv2D(128, 3, padding='same', activation='relu')(x)  # 14x14x128\n",
    "    x = layers.MaxPooling2D(2)(x)  # 7x7x128\n",
    "    x = layers.Conv2D(256, 3, padding='same', activation='relu')(x)  # 7x7x256\n",
    "    x = layers.MaxPooling2D(2)(x)  # 3x3x256\n",
    "    x = layers.Flatten()(x)\n",
    "    z = layers.Dense(128)(x)  # Latent space\n",
    "    return models.Model(inputs, z, name='encoder')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731d774a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-Net-like Decoder\n",
    "def build_decoder():\n",
    "    inputs = layers.Input(shape=(128,))\n",
    "    x = layers.Dense(256 * 3 * 3, activation='relu')(inputs)\n",
    "    x = layers.Reshape((3, 3, 256))(x)\n",
    "    x = layers.Conv2DTranspose(128, 3, strides=2, padding='same', activation='relu')(x)  # 6x6x128\n",
    "    x = layers.Conv2DTranspose(64, 3, strides=2, padding='same', activation='relu')(x)  # 12x12x64\n",
    "    x = layers.Conv2DTranspose(1, 3, strides=2, padding='same', activation='sigmoid')(x)  # 28x28x1\n",
    "    x = layers.Conv2D(1, 3, padding='valid', activation='sigmoid')(x)  # 22x22x1\n",
    "    x = layers.ZeroPadding2D(padding=((3, 3), (3, 3)))(x)  # 28x28x1\n",
    "    return models.Model(inputs, x, name='decoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0decee44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sparse Autoencoder\n",
    "class SparseAutoencoder(models.Model):\n",
    "    def __init__(self):\n",
    "        super(SparseAutoencoder, self).__init__()\n",
    "        self.encoder = build_encoder()\n",
    "        self.decoder = build_decoder()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z = self.encoder(inputs)\n",
    "        recon = self.decoder(z)\n",
    "        return recon, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca69dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contractive Autoencoder\n",
    "class ContractiveAutoencoder(models.Model):\n",
    "    def __init__(self):\n",
    "        super(ContractiveAutoencoder, self).__init__()\n",
    "        self.encoder = build_encoder()\n",
    "        self.decoder = build_decoder()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z = self.encoder(inputs)\n",
    "        recon = self.decoder(z)\n",
    "        return recon, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e0f17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_ae_loss(y_true, y_pred, z):\n",
    "    mse_loss = tf.reduce_mean(tf.keras.losses.mse(y_true, y_pred))\n",
    "    rho_hat = tf.reduce_mean(z, axis=0)    \n",
    "    rho_hat = tf.clip_by_value(rho_hat, epsilon, 1 - epsilon)\n",
    "    kl_div = rho * tf.math.log(rho / rho_hat) + (1 - rho) * tf.math.log((1 - rho) / (1 - rho_hat))\n",
    "    kl_loss = sparse_lambda * tf.reduce_sum(tf.clip_by_value(kl_div, -1e4, 1e4))  # Clip KL term\n",
    "    return mse_loss + kl_loss\n",
    "\n",
    "# Contractive Autoencoder Loss\n",
    "def contractive_ae_loss(x, recon, z, model):\n",
    "    mse_loss = tf.reduce_mean(tf.square(x - recon))\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(z)\n",
    "        recon = model.decoder(z)\n",
    "    grad_z = tape.gradient(recon, z)\n",
    "    j_loss = contractive_lambda * tf.reduce_mean(tf.reduce_sum(tf.square(grad_z), axis=1))\n",
    "    return mse_loss + j_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e2305d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add these at the beginning of your script, after imports\n",
    "# Check for GPU availability\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(f\"Found {len(gpus)} Physical GPUs, {len(logical_gpus)} Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"No GPU found, using CPU instead\")\n",
    "\n",
    "# Enable mixed precision for faster training on compatible GPUs\n",
    "if gpus:\n",
    "    tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "    print(\"Mixed precision enabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e6ab7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "def train(model, dataset, loss_fn, epochs, model_type='sparse'):\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch in dataset:\n",
    "            with tf.GradientTape() as tape:\n",
    "                recon, z = model(batch)\n",
    "                if model_type == 'sparse':\n",
    "                    loss = loss_fn(batch, recon, z)\n",
    "                else:\n",
    "                    loss = loss_fn(batch, recon, z, model)\n",
    "            gradients = tape.gradient(loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "            total_loss += loss.numpy()\n",
    "        print(f'Epoch {epoch+1}/{epochs}, {model_type.capitalize()} AE Loss: {total_loss / len(dataset):.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb86052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and compile models\n",
    "sparse_ae = SparseAutoencoder()\n",
    "contractive_ae = ContractiveAutoencoder()\n",
    "\n",
    "# Print model summary\n",
    "print(\"Sparse Autoencoder Summary:\")\n",
    "sparse_ae.summary()\n",
    "\n",
    "print(\"\\nContractive Autoencoder Summary:\")\n",
    "contractive_ae.summary()\n",
    "\n",
    "# Train Sparse Autoencoder\n",
    "print(\"Training Sparse Autoencoder...\")\n",
    "train(sparse_ae, train_dataset, sparse_ae_loss, epochs, model_type='sparse')\n",
    "\n",
    "# Train Contractive Autoencoder\n",
    "print(\"\\nTraining Contractive Autoencoder...\")\n",
    "train(contractive_ae, train_dataset, contractive_ae_loss, epochs, model_type='contractive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdb890a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to reconstruct and validate images\n",
    "def reconstruct_and_validate(model, dataset, model_name, num_images=5):\n",
    "    # Get one batch from the test dataset\n",
    "    for batch in dataset.take(1):\n",
    "        images, label = batch\n",
    "        original_images= images.numpy()\n",
    "        recon_images, _ = model(original_images, training=False)\n",
    "        recon_images = recon_images.numpy()\n",
    "\n",
    "    # Compute MSE for the batch\n",
    "    mse = np.mean((original_images - recon_images) ** 2)\n",
    "    print(f\"{model_name} Test MSE: {mse:.6f}\")\n",
    "\n",
    "    # Visualize original and reconstructed images\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    for i in range(num_images):\n",
    "        # Original image\n",
    "        plt.subplot(2, num_images, i + 1)\n",
    "        plt.imshow(original_images[i].reshape(28, 28), cmap='gray')\n",
    "        plt.title(f\"Original {i+1}\")\n",
    "        plt.axis('off')\n",
    "        # Reconstructed image\n",
    "        plt.subplot(2, num_images, i + num_images + 1)\n",
    "        plt.imshow(recon_images[i].reshape(28, 28), cmap='gray')\n",
    "        plt.title(f\"Reconstructed {i+1}\")\n",
    "        plt.axis('off')\n",
    "    plt.suptitle(f\"{model_name} Reconstruction\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"./data/{model_name}_reconstruction.png\")\n",
    "    plt.show()\n",
    "\n",
    "# After training, reconstruct and validate\n",
    "print(\"\\nReconstructing and Validating Sparse Autoencoder...\")\n",
    "reconstruct_and_validate(sparse_ae, test_dataset, \"Sparse Autoencoder\")\n",
    "\n",
    "print(\"\\nReconstructing and Validating Contractive Autoencoder...\")\n",
    "reconstruct_and_validate(contractive_ae, test_dataset, \"Contractive Autoencoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732558c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot t-SNE of embeddings\n",
    "def plot_tsne_embeddings(model, dataset, model_name, num_samples=1000):\n",
    "    # Extract embeddings and labels from test set\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "    for batch_images, batch_labels in dataset.take(num_samples // batch_size + 1):\n",
    "        z = model.encoder(batch_images, training=False).numpy()\n",
    "        embeddings.append(z)\n",
    "        labels.append(batch_labels.numpy())\n",
    "    embeddings = np.concatenate(embeddings, axis=0)[:num_samples]\n",
    "    labels = np.concatenate(labels, axis=0)[:num_samples]\n",
    "\n",
    "    # Apply t-SNE to reduce to 2D\n",
    "    tsne = TSNE(n_components=2, random_state=42, perplexity=30, n_iter=300)\n",
    "    tsne_embeddings = tsne.fit_transform(embeddings)\n",
    "\n",
    "    # Plot t-SNE with colors for each class\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x=tsne_embeddings[:, 0], y=tsne_embeddings[:, 1], hue=labels, \n",
    "                    palette='tab10', legend='full', s=50)\n",
    "    plt.title(f\"t-SNE of {model_name} Embeddings (MNIST Classes)\")\n",
    "    plt.xlabel(\"t-SNE Dimension 1\")\n",
    "    plt.ylabel(\"t-SNE Dimension 2\")\n",
    "    plt.legend(title=\"Digit\", loc=\"best\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"./data/{model_name}_tsne.png\")\n",
    "    plt.show()\n",
    "\n",
    "# After training and validation, plot t-SNE\n",
    "print(\"\\nPlotting t-SNE for Sparse Autoencoder...\")\n",
    "plot_tsne_embeddings(sparse_ae, test_dataset, \"Sparse Autoencoder\")\n",
    "\n",
    "print(\"\\nPlotting t-SNE for Contractive Autoencoder...\")\n",
    "plot_tsne_embeddings(contractive_ae, test_dataset, \"Contractive Autoencoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bed9318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute PSNR\n",
    "def compute_psnr(img1, img2, max_val=1.0):\n",
    "    mse = mean_squared_error(img1.flatten(), img2.flatten())\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    return 20 * math.log10(max_val / math.sqrt(mse))\n",
    "\n",
    "# Function to select pairs and perform interpolation analysis\n",
    "def interpolation_analysis(model, dataset, model_name, num_pairs=20, num_images_per_pair=5):\n",
    "    # Collect images and labels from test set\n",
    "    all_images, all_labels = [], []\n",
    "    for images, labels in dataset:\n",
    "        all_images.append(images.numpy())\n",
    "        all_labels.append(labels.numpy())\n",
    "    all_images = np.concatenate(all_images, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    # Randomly select pairs from different classes\n",
    "    np.random.seed(42)  # For reproducibility\n",
    "    indices = np.arange(len(all_labels))\n",
    "    np.random.shuffle(indices)\n",
    "    selected_pairs = []\n",
    "    used_labels = set()\n",
    "    i = 0\n",
    "    while len(selected_pairs) < num_pairs and i < len(indices):\n",
    "        idx1 = indices[i]\n",
    "        label1 = all_labels[idx1]\n",
    "        # Find an index with a different label\n",
    "        for j in range(i + 1, len(indices)):\n",
    "            idx2 = indices[j]\n",
    "            label2 = all_labels[idx2]\n",
    "            if label1 != label2 and (label1, label2) not in used_labels:\n",
    "                selected_pairs.append((idx1, idx2))\n",
    "                used_labels.add((label1, label2))\n",
    "                break\n",
    "        i += 1\n",
    "\n",
    "    # Alpha values for interpolation\n",
    "    alphas = [0.0, 0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "    \n",
    "    # Store metrics\n",
    "    psnr_values = {alpha: [] for alpha in alphas}\n",
    "    l2_norms = {alpha: [] for alpha in alphas}\n",
    "\n",
    "    # Process each pair\n",
    "    for pair_idx, (idx1, idx2) in enumerate(selected_pairs[:num_pairs]):\n",
    "        I1 = all_images[idx1:idx1+1]  # Shape: (1, 28, 28, 1)\n",
    "        I2 = all_images[idx2:idx2+1]\n",
    "        label1, label2 = all_labels[idx1], all_labels[idx2]\n",
    "\n",
    "        # Get embeddings h1 and h2\n",
    "        h1 = model.encoder(I1, training=False).numpy()  # Shape: (1, 64)\n",
    "        h2 = model.encoder(I2, training=False).numpy()\n",
    "\n",
    "        # Plot for this pair\n",
    "        plt.figure(figsize=(12, len(alphas) * 2))\n",
    "        for i, alpha in enumerate(alphas):\n",
    "            # Compute interpolated image Iα\n",
    "            I_alpha = alpha * I1 + (1 - alpha) * I2\n",
    "            # Compute embedding hα = E(Iα)\n",
    "            h_alpha = model.encoder(I_alpha, training=False).numpy()\n",
    "            # Compute approximate embedding h′α = αh1 + (1−α)h2\n",
    "            h_prime_alpha = alpha * h1 + (1 - alpha) * h2\n",
    "            # Decode to get Îα and Î′α\n",
    "            I_hat_alpha = model.decoder(h_alpha, training=False).numpy()\n",
    "            I_hat_prime_alpha = model.decoder(h_prime_alpha, training=False).numpy()\n",
    "\n",
    "            # Compute metrics\n",
    "            psnr = compute_psnr(I_hat_alpha[0], I_hat_prime_alpha[0])\n",
    "            l2_norm = np.sqrt(np.sum((h_alpha - h_prime_alpha) ** 2))\n",
    "            psnr_values[alpha].append(psnr)\n",
    "            l2_norms[alpha].append(l2_norm)\n",
    "\n",
    "            # Plot Îα and Î′α\n",
    "            plt.subplot(len(alphas), 2, i * 2 + 1)\n",
    "            plt.imshow(I_hat_alpha[0].reshape(28, 28), cmap='gray')\n",
    "            plt.title(f\"Îα (α={alpha:.1f})\")\n",
    "            plt.axis('off')\n",
    "            plt.subplot(len(alphas), 2, i * 2 + 2)\n",
    "            plt.imshow(I_hat_prime_alpha[0].reshape(28, 28), cmap='gray')\n",
    "            plt.title(f\"Î′α (α={alpha:.1f})\")\n",
    "            plt.axis('off')\n",
    "        \n",
    "        plt.suptitle(f\"{model_name} Pair {pair_idx+1}: Digit {label1} to {label2}\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"./data/{model_name}_pair_{pair_idx+1}.png\")\n",
    "        plt.show()\n",
    "\n",
    "    # Report average metrics\n",
    "    print(f\"\\n{model_name} Metrics:\")\n",
    "    print(\"Alpha | Avg PSNR (dB) | Avg L2 Norm\")\n",
    "    print(\"------|---------------|------------\")\n",
    "    for alpha in alphas:\n",
    "        avg_psnr = np.mean(psnr_values[alpha])\n",
    "        avg_l2_norm = np.mean(l2_norms[alpha])\n",
    "        print(f\"{alpha:.1f}  | {avg_psnr:.4f}      | {avg_l2_norm:.4f}\")\n",
    "\n",
    "# After training and other validations, perform interpolation analysis\n",
    "print(\"\\nInterpolation Analysis for Sparse Autoencoder...\")\n",
    "interpolation_analysis(sparse_ae, test_dataset, \"Sparse Autoencoder\")\n",
    "\n",
    "print(\"\\nInterpolation Analysis for Contractive Autoencoder...\")\n",
    "interpolation_analysis(contractive_ae, test_dataset, \"Contractive Autoencoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c49b8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to perform classification and evaluate embeddings\n",
    "def classify_embeddings(model, train_data, train_labels, test_data, test_labels, model_name):\n",
    "    # Extract embeddings for training set\n",
    "    train_embeddings = []\n",
    "    for batch in tf.data.Dataset.from_tensor_slices(train_data).batch(batch_size):\n",
    "        z = model.encoder(batch, training=False).numpy()\n",
    "        train_embeddings.append(z)\n",
    "    train_embeddings = np.concatenate(train_embeddings, axis=0)\n",
    "\n",
    "    # Extract embeddings for test set\n",
    "    test_embeddings = []\n",
    "    for batch, _ in test_dataset:\n",
    "        z = model.encoder(batch, training=False).numpy()\n",
    "        test_embeddings.append(z)\n",
    "    test_embeddings = np.concatenate(test_embeddings, axis=0)\n",
    "\n",
    "    # Train logistic regression classifier\n",
    "    classifier = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    classifier.fit(train_embeddings, train_labels)\n",
    "\n",
    "    # Predict on test embeddings\n",
    "    test_predictions = classifier.predict(test_embeddings)\n",
    "\n",
    "    # Compute accuracy\n",
    "    accuracy = accuracy_score(test_labels, test_predictions)\n",
    "    print(f\"{model_name} Classification Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "# After training, reconstruction, t-SNE, and interpolation analysis\n",
    "print(\"\\nClassifying Digits using Sparse Autoencoder Embeddings...\")\n",
    "sparse_accuracy = classify_embeddings(sparse_ae, x_train, y_train, x_test, y_test, \"Sparse Autoencoder\")\n",
    "\n",
    "print(\"\\nClassifying Digits using Contractive Autoencoder Embeddings...\")\n",
    "contractive_accuracy = classify_embeddings(contractive_ae, x_train, y_train, x_test, y_test, \"Contractive Autoencoder\")\n",
    "\n",
    "# Compare and report which is better\n",
    "print(\"\\nComparison:\")\n",
    "if sparse_accuracy > contractive_accuracy:\n",
    "    print(f\"Sparse Autoencoder is better with accuracy {sparse_accuracy:.4f} vs. Contractive Autoencoder {contractive_accuracy:.4f}\")\n",
    "elif contractive_accuracy > sparse_accuracy:\n",
    "    print(f\"Contractive Autoencoder is better with accuracy {contractive_accuracy:.4f} vs. Sparse Autoencoder {sparse_accuracy:.4f}\")\n",
    "else:\n",
    "    print(f\"Both autoencoders have equal accuracy: {sparse_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
